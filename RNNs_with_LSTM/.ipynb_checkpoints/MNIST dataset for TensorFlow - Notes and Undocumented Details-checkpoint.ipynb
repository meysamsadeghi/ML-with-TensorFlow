{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset\n",
    "The MNIST database of handwritten digits, available from this __[Page](http://yann.lecun.com/exdb/mnist/)__, has a training set of 60,000 examples, and a test set of 10,000 examples. The digits have been size-normalized and centered in a fixed-size image (28$\\times$28 pixels where each pixel has a value within the interval [0,1]). Let us load the mnist.\n",
    "\n",
    "There are two ways for loading MNIST dataset, each of which has its own benefits and drawbacks. In future I should make my mind and find the best way. Below re the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # we need later\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Method for Loading MNIST\n",
    "The first method for loading mnist uses **from tensorflow.examples.tutorials.mnist import input_data** command. The main issue with this approach is that it is depracted and show you warnings. So one work around (which I dont like) is to use *tf.logging* to prevent the warnings to be shown, howevere they are under the hood and it does not solve the problem.\n",
    "\n",
    "**Then what is the benefit?** The main benefit is that the object made by this way has *next_batch()* method than automatically handles the mini-batch tarining, i.e.,  it automatically handles partitioning of the input data into batches and also data shuffling. \n",
    "\n",
    "Below we can see how to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# Load data\n",
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "X_validation = mnist.validation.images\n",
    "Y_validation = mnist.validation.labels\n",
    "X_test = mnist.test.images\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **next_batch()** methodcan be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the next batch_size images array and labels\n",
    "# batch_X, batch_Y = mnist.train.next_batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Method for Loading MNIST\n",
    "The second method is the suggested way by official tensorflow __[webpage](https://www.tensorflow.org/tutorials/)__, which suggests using **mnist = tf.keras.datasets.mnist**. Its benefit is that it is up to date and the official way. But the major drawback is that it does not have something like the *netxbatch()* method and I think one should write it himself (I am not sure, there might be a way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "MNIST = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = MNIST.load_data(path='/home/meysam/github/Datasets/mnist/mnist.npz')\n",
    "# if you dont have the data downloaded\n",
    "#(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case, y_train and y_test are not one_hot encoded. Then either you should turn them into one_hot by your own function, or use tf.Keras as tensorflow tutorial, or you can use *tensorflow.python.keras._impl.keras.utils* to do one_hot encoding as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras._impl.keras.utils import np_utils # Note <from tensorflow.keras.utils import np_utils> does not work and this is just a work around. See https://github.com/tensorflow/tensorflow/issues/14008\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Difference Between Two Approaches in Terms of Data Dimenssion\n",
    "\n",
    "The first method split the data into three groups:\n",
    "- Train (55K, 784)\n",
    "- Validation (5K, 784)\n",
    "- Test (10K, 784)\n",
    "\n",
    "The second approach split the data into two groups:\n",
    "- Train (60K, 28, 28)\n",
    "- Test (10K, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Approach:\n",
      "X_train.shape: (55000, 784)\n",
      "Y_train.shape: (55000, 10)\n",
      "X_validation.shape: (5000, 784)\n",
      "X_validation.shape: (5000, 784)\n",
      "X_test.shape: (10000, 784)\n",
      "Y_test.shape: (10000, 10)\n",
      "\n",
      "Second Approach:\n",
      "x_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000, 10)\n",
      "x_test.shape: (10000, 28, 28)\n",
      "y_test.shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('First Approach:')\n",
    "print('X_train.shape:', X_train.shape)\n",
    "print('Y_train.shape:', Y_train.shape)\n",
    "print('X_validation.shape:', X_validation.shape)\n",
    "print('X_validation.shape:', X_validation.shape)\n",
    "print('X_test.shape:', X_test.shape)\n",
    "print('Y_test.shape:', Y_test.shape)\n",
    "\n",
    "print('\\nSecond Approach:')\n",
    "print('x_train.shape:', x_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('x_test.shape:', x_test.shape)\n",
    "print('y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting MNIST \n",
    "let us define a function for ploting mnist images and their class label, in a grid with desired size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func(grid_heigh,grid_width,images,lables,ShowLabel=None,ShowPred=None,Pred=None):\n",
    "    assert images.shape[0] == (grid_heigh*grid_width)\n",
    "    assert images.shape[0] == lables.shape[0]\n",
    "    if Pred is not None:\n",
    "        assert lables.shape[0] == Pred.shape[0]\n",
    "    figs, axes = plt.subplots(nrows=grid_heigh, ncols=grid_width)\n",
    "    figs.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "    for index,ax in enumerate(axes.flat): # axes.flat is required as axes has grid structure\n",
    "        ax.imshow(images[index], cmap='gray')\n",
    "        if ShowLabel:\n",
    "            ax.set_xlabel('label:{0}'.format(lables[index]))\n",
    "        if ShowPred:\n",
    "            ax.set_xlabel('label:{0}, Pred:{1}'.format(lables[index],Pred[index]))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_func(1,2,x_test[0:2],y_test[0:2],ShowLabel=True,ShowPred=None,Pred=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the **plot_func** is written for the second approach and to be used for first approach we need to revise the X shape from 784 to 28x28, and Y from 10 to 1, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_func(1,2,X_test[0:2].reshape([-1,28,28]),np.argmax(Y_test[0:2],1),ShowLabel=True,ShowPred=None,Pred=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
