{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks with TensorFlow\n",
    "In this note book we implement an LSTM based Recurrent Neural Network (RNN) classifier, for MNIST database of handwritten digits. For more useful reading on RNN try the following links. In this notebook I try to combine the good parts of all the following links while presenting a structral and classified view on RNN in TensorFlow.\n",
    "1. __[wildml's](http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/)__ post on RNNs in Tensorflow by Denny Britz. He provides an in depth understanding of RNN in TF, while discuss some undocumented issues.\n",
    "2. __[RNN_for_mnist](https://medium.com/the-artificial-impostor/notes-understanding-tensorflow-part-2-f7e5ece849f5)__ and its __[cloab_page](https://colab.research.google.com/drive/18FqI18psdH30WUJ1uPd6zVgK2AwxO_Bj#scrollTo=A-fpqklBefZy)__ by Ceshine Lee.\n",
    "3. __[Morvan_Zhou's](https://github.com/MorvanZhou/Tensorflow-Tutorial/blob/master/tutorial-contents/402_RNN_classification.py)__ RNN implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before delving into more details let us import the necessary libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset Overview\n",
    "The MNIST database of handwritten digits, available from this __[Page](http://yann.lecun.com/exdb/mnist/)__, has a training set of 60,000 examples, and a test set of 10,000 examples. The digits have been size-normalized and centered in a fixed-size image (28$\\times$28 pixels where each pixel has a value within the interval [0,1]). Let us load the mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# This other version is depracted and give warning but at least give you next batc\\nold_v = tf.logging.get_verbosity()\\ntf.logging.set_verbosity(tf.logging.ERROR)\\nfrom tensorflow.examples.tutorials.mnist import input_data\\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#One way of loading mnist given below. But it does not provide the next_batch functionality and also if you write it yourself, you should also take care of data shuffling at th end of one epoch.\n",
    "from tensorflow.python.keras._impl.keras.utils import np_utils # Note <from tensorflow.keras.utils import np_utils> does not work and this is just a work around. See https://github.com/tensorflow/tensorflow/issues/14008\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data(path='/home/meysam/github/Datasets/mnist/mnist.npz')\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "'''\n",
    "# This other version is depracted and give warning but at least give you next batc\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nextBatch(batch_size,inputs,labels,batch_num):\n",
    "    len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us define a function for ploting mnist images and their class label, in a grid with desired size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func(grid_heigh,grid_width,images,lables,ShowLabel=None,ShowPred=None,Pred=None):\n",
    "    assert images.shape[0] == (grid_heigh*grid_width)\n",
    "    assert images.shape[0] == lables.shape[0]\n",
    "    if Pred is not None:\n",
    "        assert lables.shape[0] == Pred.shape[0]\n",
    "    figs, axes = plt.subplots(nrows=grid_heigh, ncols=grid_width)\n",
    "    figs.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "    for index,ax in enumerate(axes.flat): # axes.flat is required as axes has grid structure\n",
    "        ax.imshow(images[index], cmap='gray')\n",
    "        if ShowLabel:\n",
    "            ax.set_xlabel('label:{0}'.format(lables[index]))\n",
    "        if ShowPred:\n",
    "            ax.set_xlabel('label:{0}, Pred:{1}'.format(lables[index],Pred[index]))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_func(1,2,x_test[0:2],y_test[0:2],ShowLabel=True,ShowPred=None,Pred=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Based RNN in TensorFlow - A Closer Look into Details\n",
    "In order to implement any RNN in TF, we need to clearly determine two things:\n",
    "1. The RNN itself, which we can either use a static or a dynamic RNN, as shown below.\n",
    "    1. tf.contrib.rnn.static_rnn (or its aliase tf.nn.static_rnn) \n",
    "    2. tf.nn.dynamic_rnn\n",
    "2. The cell that is being used by the RNN, which also can have many different implementations as shown below:\n",
    "    1. tf.nn.rnn_cell.BasicLSTMCell (aliase with 2) (this one is deprecated)\n",
    "    2. tf.contrib.rnn.BasicLSTMCell (aliase with 1) (this one is deprecated)\n",
    "    3. tf.contrib.rnn.LSTMCell (which is an aliase of 4)\n",
    "    4. tf.nn.rnn_cell.LSTMCell (which is an aliase of 3)\n",
    "    5. tf.contrib.rnn.LSTMBlockCell\n",
    "    6. tf.contrib.rnn.LSTMBlockFusedCell\n",
    "So, the question is which RNN (static or dynamic) and which LSTM cell (6 cases) shall we use? This is discussed belwo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static VS Dynamic RNN:\n",
    "Here we explain whether we use static or dynamic RNN. In short, it is better to use dynamic RNN while we should be careful when we have inputs with different length (number of time steps). \n",
    "\n",
    "Static RNN creates an unrolled graph for a fixed RNN length. That means, if you call tf.nn.rnn with inputs having 200 time steps you are creating a static graph with 200 RNN steps. First, graph creation is slow. Second, you’re unable to pass in longer sequences (> 200) than you’ve originally specified. \n",
    "\n",
    "*tf.nn.dynamic_rnn* solves this. It uses a tf.While loop to dynamically construct the graph when it is executed. That means graph creation is faster and you can feed batches of variable size. So dynamic RNN is faster and more flexible.\n",
    "\n",
    "Also, based on __[here](https://medium.com/the-artificial-impostor/notes-understanding-tensorflow-part-2-f7e5ece849f5)__, we can supply the whole batch of input data as a tensor to dynamic_rnn instead of slicing them into a list of tensor (sequences). This is easier to write and read than static_rnn. See the code below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# input shape: (batch_size, length (num of time steps), ..(the rest of dimenssions depends on the input data)..)\n",
    "# Static RNN is like below\n",
    "x = tf.unstack(x, timesteps, 1) <==> This requires to manually take care of shape of the input batch\n",
    "lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "# Dynamic RNN is like below\n",
    "outputs, _ = tf.nn.dynamic_rnn(cell=lstm_cell, inputs=x, time_major=False, dtype=tf.float32)\n",
    "\n",
    "# Note for time_major ==> False: (batch, time step, input); True: (time step, batch, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Important Note on the shape of the input and outputs for RNN (tf.nn.dynamic_rnn) </b>:\n",
    "    \n",
    "If time_major == False (default mode) then \n",
    "- input must be a Tensor of shape: [batch_size, max_time, ...], or a nested tuple of such elements.\n",
    "- outputs will be a Tensor shaped: [batch_size, max_time, cell.output_size]\n",
    "- state: The final state. If cell.state_size is an int, this will be shaped [batch_size, cell.state_size]. If it is a TensorShape, this will be shaped [batch_size] + cell.state_size\n",
    "\n",
    "For exampl let’s say you have a batch of two examples, one is of length 13, and the other of length 20. Each one is a vector of 128 numbers. The length 13 example is 0-padded to length 20. Then your RNN input tensor is of shape [2, 20, 128]. The dynamic_rnn function returns a tuple of (outputs, state), where outputs is a tensor of size [2, 20, ...] with the last dimension being the RNN output at each time step. state is the last state for each example, and it’s a tensor of size [2, ...] where the last dimension also depends on what kind of RNN cell you’re using.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Using Dynam RNN Requires Caution if we have inputs with different length (time steps)</b>: In the above example, once you reach time step 13, your first example in the batch is already “done” and you don’t want to perform any additional calculation on it. The second example isn’t and must go through the RNN until step 20. Hence we need to pass something called sequence_length. By passing sequence_length=[13,20] you tell Tensorflow to stop calculations for example 1 at step 13 and simply copy the state from time step 13 to the end. The output will be set to 0 for all time steps past 13. You’ve just saved some computational cost. But more importantly, if you didn’t pass sequence_length you would get incorrect results! Without passing sequence_length, Tensorflow will continue calculating the state until T=20 instead of simply copying the state from T=13. This means you would calculate the state using the padded elements, which is not what you want.\n",
    "</div>\n",
    "\n",
    "For example if we have an input batch X with two inputs and length of first one is 10 and second is 6 as below, then here is how we pass the sequence_length to the tf.nn.dynamic_rnn."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = np.random.randn(2, 10, 8) # we create a batch \n",
    "X[1,6:] = 0 # Force the second example to be of length 6\n",
    "X_lengths = [10, 6] # here we create the vector to be passed as sequence_length\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_units=64, state_is_tuple=True)\n",
    "outputs, last_states = tf.nn.dynamic_rnn(cell=cell,dtype=tf.float64,sequence_length=X_lengths,inputs=X)\n",
    "result = tf.contrib.learn.run_n({\"outputs\": outputs, \"last_states\": last_states},n=1,feed_dict=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also further discussion on dynamic and static RNN can be found at __[stackoverflow](https://stackoverflow.com/questions/39734146/whats-the-difference-between-tensorflow-dynamic-rnn-and-rnn)__, __[github](https://github.com/tensorflow/tensorflow/issues/3801)__. Also some further discussions on RNN with tensorflow is avaliable at __[wildml](http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/)__ and __[Here](https://medium.com/the-artificial-impostor/notes-understanding-tensorflow-part-2-f7e5ece849f5)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Choice of LSTM Cell:\n",
    "For LSTM we intrduced 6 cases, but as the first two implementations are depracted and the third and fourth are aliases, we have 3 major options. A detailed discussion on these cases can be found in this __[page](https://returnn.readthedocs.io/en/latest/tf_lstm_benchmark.html)__. \n",
    "1. tf.nn.rnn_cell.LSTMCell  \n",
    "2. tf.contrib.rnn.LSTMBlockCell\n",
    "3. tf.contrib.rnn.LSTMBlockFusedCell\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "tf.contrib contains volatile and experimental code, and at some point it will be removed. While, tf.nn is said to contain wrappers for primitive neural net operations, and hence is more reliable. Refer to TF official page and check their explanation on the API for details.\n",
    "</div>\n",
    "\n",
    "Also, based on my check from tensorflow documentaion, *tf.nn.rnn_cell.LSTMCell* receives more arguments (e.g. state_is_tuple=True). Hence it looks like a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Implementation\n",
    "Now we implement an LSTM based RNN to classify MNIST. I suggest to take a look at colah's __[Page](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)__ for further discussions on LSTM. \n",
    "\n",
    "In what follows, we implement a single layer RNN network with LSTM cells with the following parameters:\n",
    "- num_hidden $\\leftrightarrow$ is the number of neurons for each neural network within the LSTM cell. Note that LSTM has 4 neural nets within itself. \n",
    "- num_steps $\\leftrightarrow$ is the number of time steps we consider for our RNN\n",
    "- num_input $\\leftrightarrow$ is the dimenssion of the each input, or equivalently, the number of features. \n",
    "\n",
    "As a side practice try to count the number of parameters that we have by (4 ((num_input + num_hidden ) x num_hidden+1)), as we have 4 neural network in one LSTMM cell, each of which has an input size of (num_input + num_hidden) where the former is due to input and the latter is due to the activation comming from previous layer. Also at the hidden layer we have num_hidden neurons and one bias parameter.\n",
    "Let us now write the model. First we need to initialze some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # in the begining of the code to avoid namespace error\n",
    "num_hidden = 64\n",
    "num_steps = 28  # as we want to read the images column by column\n",
    "num_input = 28 # as one column of image is 28 pixels\n",
    "num_classes = num_classes # 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE</b>: Tensorflow’s RNN functions expect a tensor of shape [B, T, ...] as input, where B is the batch size and T is the length in time of each input (e.g. the number of words in a sentence, or num_steps). The last dimensions depend on your data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, num_steps, num_inputs])\n",
    "Y = tf.placeholder(tf.float32,[None,num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_model(x,num_classes): \n",
    "    \n",
    "    \n",
    "    # Define an lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units = num_hidden,state_is_tuple=True) #lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, last_states = tf.nn.dynamic_rnn(cell=lstm_cell,  # an instance of RNN cell\n",
    "                                             inputs=x,        # The RNN inputs. If time_major == False (default), this must be a Tensor of shape: [batch_size, max_time, ...], or a nested tuple of such elements\n",
    "                                             dtype=tf.float32 # It is NOT optional, if we do not provide \n",
    "                                             # sequence_length = sequence_length # this one is optional (read the note above on sequence_length). When all our input data points have the same number of time steps\n",
    "                                             # time_major = False # It is optional. time_major determines the shape format of the inputs and outputs Tensors. If true, these Tensors must be shaped [max_time, batch_size, depth]. If false, these Tensors must be shaped [batch_size, max_time, depth].\n",
    "                                            )\n",
    "    # outputs: is the RNN output tensor. If time_major == False (default), this will be a Tensor shaped: [batch_size, max_time, cell.output_size]\n",
    "    #last_states:is the final state of RNN.  cell.state_size is an int, this will be shaped [batch_size, cell.state_size]. If it is a TensorShape, this will be shaped [batch_size] + cell.state_size\n",
    "    \n",
    "    \n",
    "    output_layer = tf.layers.Dense(\n",
    "        num_classes, activation=None, \n",
    "        kernel_initializer=tf.orthogonal_initializer()\n",
    "    )\n",
    "    return output_layer(tf.layers.batch_normalization(outputs[:, -1, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were interested in a bidirectional RNN with LSTM cells, check this __[page](http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/)__. Now let us create the graph,."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = RNN_model(x,num_classes)\n",
    "predictions = tf.nn.softmax(logits)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y,logits=logits))\n",
    "optimizer = tf.train.AdamOptimizer().minize(cost)\n",
    "\n",
    "accuracy = tf.reduce_mean( (tf.cast(tf.equal(tf.argmax(predictions,1), tf.argmax(Y,1)),dtype=tf.float32)) )\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Sess() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "                          \n",
    "                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
